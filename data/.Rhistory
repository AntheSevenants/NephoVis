install.packages(c("knitr", "rmdformats", "kfigr", "kableExtra", "RColorBrewer"))
library(tidyverse)
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.mds.tsv", col_types = cols())
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.mds.tsv", col_types = cols()) %>% pull("_id")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.mds.tsv", col_types = cols()) %>% pull("_id") %>% head
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% pull("_id") %>% head
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "de_standaard_20000807_01_49/470")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "de_standaard_20000807_01_49/470") %>% select("_ctxt.raz")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "de_standaard_20000807_01_49/470") %>% select("_ctxt.raw")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "de_standaard_20000807_01_49/470") %>% select("_id")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "horde/noun/de_standaard_20000807_01_49/470") %>% select("_id")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "horde/noun/de_standaard_20000807_01_49/470") %>% select("_ctxt.raw")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "horde/noun/de_standaard_20000807_01_49/470") %>% select("_ctxt.horde.foc10.nav.no_ppmi.bound.min1")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "horde/noun/de_standaard_20000807_01_49/470") %>% select("_ctxt.horde.foc10.nav.no_ppmi.bound")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "horde/noun/de_standaard_20000807_01_49/470") %>% pull("_ctxt.horde.foc10.nav.no_ppmi.bound")
read_tsv("../GitHub/montesmariana.github.io/NephoVis/data/horde/horde.variables.tsv", col_types = cols()) %>% filter(`_id` == "horde/noun/de_standaard_20000807_01_49/470") %>% pull("_cws.horde.foc10.nav.no_ppmi.bound")
read_tsv("../Concordances/horde.tsv", col_types = cols())
read_tsv("../Concordances/horde.tsv", col_types = cols()) %>% filter(token_id === "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Concordances/horde.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Merges/token_annotation.tsv", col_types = cols())
read_tsv("../Merges/long_tokens.tsv", col_types = cols())
read_tsv("../Merges/long_tokens.tsv", col_types = cols()) %>% filter(token_id == "de_standaard_20000807_01_49/470")
read_tsv("../Merges/long_tokens.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Type annotations/horde/horde_1.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Type annotations/horde/horde_2.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Type annotations/horde/horde_".tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Type annotations/horde/horde_3.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Type annotations/horde/horde_4.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Type annotations/horde/horde_5.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Type annotations/horde/horde_6.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470")
read_tsv("../Merges/long_tokens.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/470") %>% pull("old_id")
read_tsv("../Type annotations/horde/horde_1.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444<")
read_tsv("../Type annotations/horde/horde_1.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444")
read_tsv("../Type annotations/horde/horde_2.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444")
read_tsv("../Type annotations/horde/horde_".tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444")
read_tsv("../Type annotations/horde/horde_3.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444")
read_tsv("../Type annotations/horde/horde_4.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444")
read_tsv("../Type annotations/horde/horde_5.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444")
read_tsv("../Type annotations/horde/horde_6.tsv", col_types = cols()) %>% filter(token_id == "horde/noun/de_standaard_20000807_01_49/444")
library(knitr)
library(rmdformats)
library(kfigr)
library(kableExtra)
library(tidyverse)
library(RColorBrewer)
## Global options
options(max.print="75", scipen = 999)
opts_chunk$set(echo=FALSE,
cache=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_hooks$set(fig.cap = function(options){
# in this figr, the first TRUE indicates full caption (include 'Figure')
# FALSE points to adding a link (TRUE when I reference in text)
# the first and last arguments retrieve options from the chunk
first_part = figr(options$label, TRUE, FALSE, options$anchor)
text = options$fig.cap
options$fig.cap = paste0(first_part, ". ", text)
options
})
opts_knit$set(width=75)
plot_full_model(models, 'foc_window', 'foc_part_of_speech', 'stress')
unlink('nouns_cache', recursive = TRUE)
setwd("C:/xampp/htdocs/GitHub/montesmariana.github.io/Annotation/")
dir()
library(tidyverse)
dir(pattern = ".+batch-.+tsv")
map_dbl(dir(pattern = ".+batch-.+tsv"), function (x) {read_tsv(x, col_types=cols()) %>% nrow}
map_dbl(dir(pattern = ".+batch-.+tsv"), function (x) {read_tsv(x, col_types=cols()) %>% nrow})
map_dbl(dir(pattern = ".+batch-.+tsv"), function (x) {read_tsv(x, col_types=cols()) %>% select(token_id) %>% unique %>% nrow()})
map_dbl(dir(pattern = ".+batch-.+tsv"), function (x) {read_tsv(x, col_types=cols()) %>% select(id) %>% unique %>% nrow()})
map_dbl(dir(pattern = ".+batch-.+tsv"), function (x) {read_tsv(x, col_types=cols()) %>% nrow})
map_dbl(dir(pattern = ".+batch-.+tsv"), function (x) {read_tsv(x, col_types=cols()) %>% select(id) %>% unique %>% nrow()})
setwd("C:/xampp/htdocs/GitHub/montesmariana.github.io/NephoVis/data/")
library(tidyverse)
dir()
lemmas <- dir()[dir() %in% c("church", "zwart", "procrustes_register.tsv")]
lemmas
lemmas <- dir()[!dir() %in% c("church", "zwart", "procrustes_register.tsv")]
lemmas
i <- 1
lemmas[i]
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% pull("_id")
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.5.tsv"), col_types = cols()) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.20.tsv"), col_types = cols()) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.20.tsv"), col_types = cols()) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.30.tsv"), col_types = cols()) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.50.tsv"), col_types = cols()) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.50.tsv"), col_types = cols()) %>% arrange(`_id`) %>% pull("_id") %>% head()
proper_order <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% pull("_id")
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.50.tsv"), col_types = cols()) %>% arrange(`_id`) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.20.tsv"), col_types = cols()) %>% arrange(`_id`) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.30.tsv"), col_types = cols()) %>% arrange(`_id`) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".tsne.5.tsv"), col_types = cols()) %>% arrange(`_id`) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% arrange(`_id`) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()))
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols())) %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id") %>% pull("_id") %>% head()
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id") %>% pull("_id") %>% select(-ends_with(".x"), -ends_with(".y"))
read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id") %>% select(-ends_with(".x"), -ends_with(".y"))
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged %>% select(-ends_with(".x"), -ends_with(".y"))
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
i <- i+1
lemmas[i]
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged
merged %>% pull("_id") %>% head()
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
i <- i+1
lemmas[i]
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged %>% pull("_id") %>% head()
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
i <- i+1
lemmas[i]
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
i <- i+1
lemmas[i]
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
i <- i+1
lemmas[i]
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
i <- i+1
lemmas[i]
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
i <- i+1
lemmas[i]
merged <- read_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"), col_types = cols()) %>% select("_id", ends_with(".x"), ends_with(".y")) %>% left_join(read_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"), col_types = cols()), by="_id")
merged %>% pull("_id") %>% head()
merged %>% select(-ends_with(".x"), -ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".variables.tsv"))
merged %>% select("_id", ends_with(".x"), ends_with(".y")) %>% write_tsv(paste0(lemmas[i], "/", lemmas[i], ".mds.tsv"))
lemmas[i]
i <- i+1
lemmas[i]
unlink('~/Annotation/nouns_cache', recursive = TRUE)
github_dir <- "C:/xampp/htdocs/GitHub/montesmariana.github.io/NephoVis/data/"
l <- "hoop"
library(knitr)
library(rmdformats)
library(kfigr)
library(kableExtra)
library(tidyverse)
library(RColorBrewer)
## Global options
options(max.print="75", scipen = 999)
opts_chunk$set(echo=FALSE,
cache=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_hooks$set(fig.cap = function(options){
# in this figr, the first TRUE indicates full caption (include 'Figure')
# FALSE points to adding a link (TRUE when I reference in text)
# the first and last arguments retrieve options from the chunk
first_part = figr(options$label, TRUE, FALSE, options$anchor)
text = options$fig.cap
options$fig.cap = paste0(first_part, ". ", text)
options
})
opts_knit$set(width=75)
clouds <- read_tsv(paste0(github_dir, l, '/', l, '.tsv'))
clouds <- read_tsv(paste0(github_dir, l, '/', l, '.variables.tsv'))
pull(filter(clouds, clouds$'_id' == 'hoop/noun/het_nieuwsblad_20001017_01_561/893'), 'popular')
pull(filter(clouds, clouds$'_id' == 'hoop/noun/het_laatste_nieuws_20001017_01_561/893'), 'popular')
pull(filter(clouds, clouds$'_id' == 'hoop/noun/het_laatste_nieuws_20001017_01_561/893'), 'mean_conf')
pull(filter(clouds, clouds$'_id' == 'hoop/noun/het_laatste_nieuws_20001017_01_561/893'), 'pop_conf')
max(clouds$pop_conf)
max(clouds$pop_conf, na.rm = T)
pull(filter(clouds, clouds$'_id' == 'hoop/noun/het_laatste_nieuws_20001017_01_561/893'), 'pop_agree')
max(clouds$pop_agree, na.rm = T)
library(knitr)
library(rmdformats)
library(kfigr)
library(kableExtra)
library(tidyverse)
library(RColorBrewer)
## Global options
options(max.print="75", scipen = 999)
opts_chunk$set(echo=FALSE,
cache=TRUE,
prompt=FALSE,
tidy=TRUE,
comment=NA,
message=FALSE,
warning=FALSE)
opts_hooks$set(fig.cap = function(options){
# in this figr, the first TRUE indicates full caption (include 'Figure')
# FALSE points to adding a link (TRUE when I reference in text)
# the first and last arguments retrieve options from the chunk
first_part = figr(options$label, TRUE, FALSE, options$anchor)
text = options$fig.cap
options$fig.cap = paste0(first_part, ". ", text)
options
})
opts_knit$set(width=75)
input_dir <- "./Merges/"
concordance_dir <- "./Concordances/Final/"
root <- "C:/" # My personal computer
# root <- "C:/Users/u0118974/" # My work computer
github_dir <- paste0(root, "xampp/htdocs/GitHub/montesmariana.github.io/NephoVis/data/")
types <- read_tsv(paste0(input_dir, "types.tsv"), col_types = cols()) %>% filter(pos == 'noun')
tokens <- read_tsv(paste0(input_dir, "token_annotation.tsv"), col_types = cols()) %>%
filter(type %in% types$type)
agreement <- read_tsv(paste0(input_dir, "long_tokens.tsv"), col_types = cols()) %>%
filter(type %in% types$type)
definitions <- read_tsv(paste0(input_dir, "definitions.tsv"), locale = locale(encoding = 'latin1'), col_types = cols()) %>%
filter(lemma %in% types$type)
lemmas <- read_tsv(paste0(github_dir, 'procrustes_register.tsv'), col_types = cols())
tokens
agreement
agreement %>% filter(type == "spot", sense == "other_sense", agree_fct = "minority")
agreement %>% filter(type == "spot", sense == "other_sense", agree_fct == "minority")
agreement %>% filter(type == "spot", sense == "other_sense", agree_fct == "minority") %>% pull(token_id) %>% unique()
magazine <- agreement %>% filter(type == "spot", sense == "other_sense", agree_fct == "minority") %>% pull(token_id) %>% unique()
clouds
l <- "spot"
clouds <- read_tsv(paste0(github_dir, l, '/', l, '.variables.tsv'))
clouds %>% filter(`_id` %in% magazine)
clouds %>% filter(`_id` %in% magazine) %>% pull("_ctxt.raw")
magazine
clouds
pull(filter(clouds, clouds$'_id' == 'spot/noun/het_nieuwsblad_20031029_01_144/9'), '_ctxt.spot.foc10.all.no_ppmi.bound')
filter(clouds, clouds$'_id' == 'spot/noun/het_nieuwsblad_20031029_01_144/9')
filter(clouds, clouds$'_id' == 'spot/noun/het_nieuwsblad_20031029_01_144/9') %>% nrow()
filter(clouds, clouds$'_id' == "spot/noun/het_nieuwsblad_20031029_01_144/9") %>% nrow()
filter(clouds, clouds$'_id' == "spot/noun/het_nieuwsblad_20041020_01_8/9") %>% nrow()
unlink('~/Annotation/nouns_cache', recursive = TRUE)
unlink('~/Annotation/nouns_cache', recursive = TRUE)
input_dir <- "./Merges/"
concordance_dir <- "./Concordances/Final/"
root <- "C:/" # My personal computer
# root <- "C:/Users/u0118974/" # My work computer
github_dir <- paste0(root, "xampp/htdocs/GitHub/montesmariana.github.io/NephoVis/data/")
types <- read_tsv(paste0(input_dir, "types.tsv"), col_types = cols()) %>% filter(pos == 'noun')
tokens <- read_tsv(paste0(input_dir, "token_annotation.tsv"), col_types = cols()) %>%
filter(type %in% types$type)
agreement <- read_tsv(paste0(input_dir, "long_tokens.tsv"), col_types = cols()) %>%
filter(type %in% types$type)
definitions <- read_tsv(paste0(input_dir, "definitions.tsv"), locale = locale(encoding = 'latin1'), col_types = cols()) %>%
filter(lemma %in% types$type)
lemmas <- read_tsv(paste0(github_dir, 'procrustes_register.tsv'), col_types = cols())
geen_senses <- list(
"other_sense" = "The sense of this token is not included in the definitions",
"wrong_lemma" = "The spelling, lemma and/or part-of-speech are wrong",
"unclear" = "The context is not enough; I don't understand",
"no_agreement" = "Not two annotators agreed on the same tag"
)
find_definition <- function(s) {
if (s %in% definitions$code) {
return(pull(filter(definitions, code == s), "definition"))
} else if (s %in% names(geen_senses)) {
return(geen_senses[[s]])
} else {
return("")
}
}
create_sense_matrix <- function(lemma, weight) {
# Extract the senses for that lemma and create empty matrix
senses <- tokens %>% filter(type == lemma, popular != 'no_agreement') %>% pull(popular) %>% unique
senses <- c(sort(senses[startsWith(senses, lemma)]), sort(senses[!startsWith(senses, lemma)]), 'no_agreement', 'total')
cols <- agreement %>% filter(type == lemma) %>% pull(sense) %>% unique
cols <- c(sort(cols[startsWith(cols, lemma)]), sort(cols[!startsWith(cols, lemma)]), 'total')
sense_matrix <- matrix(nrow=length(senses), ncol = length(cols),
dimnames = list(senses, cols))
sense_matrix[is.na(sense_matrix)] <- 0
confidence_matrix <- sense_matrix[1:dim(sense_matrix)[1]-1, 1:dim(sense_matrix)[2]-1]
# Subset the token information for that lemma
subset <- agreement %>% filter(type == lemma)
for (t in unique(subset$token_id)) { # for each token
# Extract the assigned senses
tagged_senses <- subset %>% filter(token_id == t) %>% pull(sense)
confidences <- subset %>% filter(token_id == t) %>% pull(confidence)
p <- tokens %>% filter(token_id == t) %>% pull(popular)
#Update values in matrices
for (s in unique(tagged_senses)) {
sense_matrix[p, s] <- sense_matrix[p, s]+1
sense_matrix['total', s] <- sense_matrix['total', s]+1
confidence_matrix[p, s] <- confidence_matrix[p, s]+mean(confidences[which(tagged_senses == s)])
}
sense_matrix[p, 'total'] <- sense_matrix[p, 'total']+1
}
confidence_matrix <- confidence_matrix/sense_matrix[1:dim(sense_matrix)[1]-1, 1:dim(sense_matrix)[2]-1]
confidence_matrix[is.nan(confidence_matrix)] <- 0
confidence_matrix <- round(confidence_matrix, 2)
if (weight) {
tb <- bind_cols(senses = row.names(confidence_matrix), as_tibble(confidence_matrix)) %>%
mutate_if(is.numeric, function(x) {
cell_spec(x,
color=if_else(
x == 0, "#bdbdbd", if_else(
x >= 4, "#006d2c","#2ca25f")),
bold=if_else(x>=4, TRUE, FALSE))
})
} else {
tb <- bind_cols(senses = row.names(sense_matrix), as_tibble(sense_matrix)) %>%
mutate_if(is.numeric, function(x) {cell_spec(x, color=if_else(x == 0, "#bdbdbd","#000000"))})
}
tb <- tb %>% mutate(
senses = cell_spec(senses,
popover = spec_popover(
content = find_definition(senses),
position = "right"
))
)
return(tb)
}
add_estimates <- function(l) {
d <- definitions %>% filter(lemma == l)
my_dist <- as.character(flatten(map2(d$code, d$freq, rep)))
return(c(my_dist, rep('geen', 40-sum(d$freq))))
}
add_overall <- function(l) {
toks <- tokens %>% filter(type == l)
tab <- toks %>% mutate(popular = if_else(startsWith(popular, l), popular, 'geen')) %>%
count(popular) %>% mutate(n = round(n/length(unique(toks$batch)), 0)) %>% deframe
if (sum(tab) < 40) {tab['geen'] <- tab['geen'] + 40-sum(tab)}
return(rep(names(tab), tab))
}
cbPalette <- c("#56B4E9", "#E69F00", "#009E73", "#F0E442", "#D55E00", "#0072B2", "#999999", "#CC79A7", "#000000")
pop_per_batch <- function(lemma, task) {
counts <- tokens %>%
filter(type == lemma) %>%
select(popular, batch, pop_conf) %>%
mutate(
popular = if_else(startsWith(popular, lemma), popular, 'geen'),
batch = str_replace(batch, "[a-z]+(_[0-9])", "batch\\1")) %>%
bind_rows(tibble(batch = 'estimate', popular = add_estimates(lemma), pop_conf = 1)) %>%
bind_rows(tibble(batch = 'overall', popular = add_overall(lemma), pop_conf = 1)) %>%
group_by(popular, batch) %>%
mutate(n = n()) %>% ungroup
if (task == 'table') {
tab <- counts %>%
select(popular, batch, n) %>% unique() %>%
spread(key = batch, value = n, fill = 0) %>%
rename(sense = popular)
return(tab)
} else if (task == 'plot') {
counts %>%
select(popular, batch, pop_conf) %>%
arrange(popular, desc(pop_conf)) %>%
group_by(batch) %>%
mutate(n = seq(n())) %>% ungroup() %>% mutate(batch = fct_reorder(batch, desc(batch))) %>%
ggplot() +
geom_point(
aes(x = batch, y = n, color=popular, alpha = pop_conf),
size = 3
) +
geom_segment(aes(x = 2.5, xend = 2.5, y = 0, yend = 40)) +
scale_color_manual(values = cbPalette) +
labs(
y = "Tokens",
x = "Batch",
color = "Popular sense",
alpha = "Mean confidence"
) +
theme(panel.grid = element_blank(),
panel.background = element_rect(fill = "white")) +
coord_flip()
}
}
comment_concordance <- function(lemma, sensetag = 'geen', original = TRUE, extratag = 'comments') {
t_text <- read_tsv(paste0(concordance_dir, lemma, ".tsv"), col_types = cols()) %>%
select(id, left, target, right)
if (original) {
subset <- agreement %>% filter(type == lemma, original_sense == origtag)
} else {
subset <- agreement %>% filter(type == lemma, sense = sensetag)
}
concordance <- subset %>%
mutate(comments = map2_chr(token_id, annotator, function(t, c) {
col <- str_replace(c, "[0-9]+(_[1-4])", paste0(extratag, "\\1"))
com <- tokens %>%
filter(token_id == t) %>%
pull(col)
return(com)
})) %>%
arrange(desc(agree_nr), token_id) %>%
select(id = token_id, annotator, comment = comments, num = agree_nr) %>%
left_join(t_text, by="id")
return(concordance)
}
popularity_contest <- function(lemma, granularity='sense') {
if (granularity == 'sense') {
pop <- quo(popular); ag <- quo(pop_agree)
} else if (granularity == 'homo') {
pop <- quo(homonym); ag <- quo(agree_homo)
}
tab <- tokens %>% filter(type == lemma) %>%
group_by(!!pop) %>% mutate(sense_count = n()) %>%
filter(!!ag == 1) %>% mutate(agree_count = round(n()/sense_count, 2)) %>% ungroup() %>%
select(!!pop, agree_count) %>% unique %>% deframe
return(tab)
}
group_homonyms <- function(lemma, granularity = 'sense') {
if (granularity == 'sense') {
df <- agreement; pop <- quo(sense)
} else if (granularity == 'popular') {
df <- tokens; pop <- quo(popular)
}
tab <- df %>% filter(type == lemma) %>%
select(!!pop, homonym) %>% unique %>%
count(homonym)
res <- tab %>% filter(homonym != "geen") %>%
mutate(homonym = map_chr(homonym, ~homonym_names[[.]]))
if ('geen' %in% tab$homonym) {
res <- bind_rows(res, filter(tab, homonym == 'geen'))
}
return(deframe(res))
}
show_sense_matrix <- function(lemma) {
sm <- create_sense_matrix(lemma, FALSE)
pop_sense <- popularity_contest(l); pop_homo <- popularity_contest(l, 'homo')
homo_names <- map_chr(names(pop_homo), ~homonym_names[[.]])
capt <- paste0("Non weighted sense matrix of '", l, "' senses.")
popS <- paste0("Proportion of tokens with full agreement per sense-tag is: ",
paste(str_c(names(pop_sense), ':'), pop_sense, collapse = ', '), '.')
popH <- paste0("Proportion of tokens with full agreement per homonym is: ",
paste(str_c(homo_names, ':'), pop_homo, collapse = ', '), '.')
kable(sm, escape = F, digits = 2, caption = capthis(paste(capt, popS, popH))) %>%
kable_styling("condensed", full_width = F) %>%
column_spec(length(colnames(sm)), background="#e0e0d1") %>%
row_spec(nrow(sm), background = "#e0e0d1") %>%
add_header_above(c('', group_homonyms(l, 'sense'), ''))
}
plot_full_model <- function(df, cl, sh = NULL, sz = 3) {
g <- ggplot(df,
aes_string(x = 'model.x', y = 'model.y', color = cl, shape = sh, size = sz)) +
geom_point() +
scale_size(range = c(1, 4)) +
scale_color_manual(values = cbPalette) +
theme_classic() +
guides(color = guide_legend(override.aes = list(size = 3)),
shape = guide_legend(override.aes = list(size = 3))) +
labs(x = '1st dimension', y = '2nd dimension')
if (sz == 3) { g <- g + guides(size = FALSE) }
return(g)
}
definitions
find_definition("blik_1")
find_definition("spot_1")
find_definition("unclear")
x <- c("blik_1", "stof_4", "no_agreement", "hoop_3")
find_definition(x)
map_chr(x, find_definition)
unlink('~/Annotation/nouns_cache', recursive = TRUE)
lubridate::date(Sys.Date())
